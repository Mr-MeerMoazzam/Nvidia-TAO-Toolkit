
# Nvidia TAO Toolkit

The NVIDIA TAO Toolkit, which is based on TensorFlow and PyTorch, makes use of the power of transfer learning while accelerating the model-training process and optimising the model for inference throughput on the target platform. It produces a workflow that is incredibly efficient. Take your own models or pre-trained models, modify them to your own real or synthetic data, and then optimise for inference throughput. All without the requirement for AI knowledge or large training datasets.

In a nutshell, it's used to build extremely accurate, customizable, and production-ready AI models to power your speech and computer vision AI applications. In this repo, you will find all about Nvidia TAO Toolkit.



![Logo](https://docs.nvidia.com/metropolis/TLT/tlt-user-guide/_static/nv_logo.png)




## Workflow

- Bring your own model weights or use Nvidia's.

- Rapidly train, adapt, and optimise the model.
- Integrate and deploy the customised model into your application.


![TAO Workflow](https://developer.nvidia.com/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png)



## Key Benefits

- Faster Model Training
- Develop Highly Accurate AI
- Inference Optimization
- Ease in deployment

## Key Feature

- Integrate TAO Toolkit into Your Application Using Rest APIs
- Using AutoML, simplify AI
- Run on your preferred cloud
- Improve AI Workflow by Integrating MLOPs



## Nvidia's Pretrained AI Models

Nvidia has hundreds of AI pre-trained models for the ease of developers. Pretrained AI Models have been fine-tuned with weights and biases after being trained on representative datasets. These models can be quickly and readily customised using a fraction of the real-world or synthetic data required to train from scratch.
You can explore more about Pretrained [Computer Vision AI Models](https://docs.nvidia.com/tao/tao-toolkit/text/overview.html#tao-computer-vision-workflow-overview) and [Conversationa AI Models](https://docs.nvidia.com/tao/tao-toolkit/text/overview.html#tao-conversational-ai-workflow-overview) here.
## Inference Performance of Nvidia's AI Models

With NVIDIA pretrained models, you can maximise inference performance on all platforms, including the cloud with GPUs built on the NVIDIA Ampere architecture and the edge with NVIDIA JetsonTM solutions. Check out the thorough [Performance Datasheet](https://docs.nvidia.com/tao/tao-toolkit/text/model_zoo/overview.html#performance-metrics) for more information on batch size and other models.
## Acknowledgements

 - [Official Documentation](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/resources/tao-getting-started)

